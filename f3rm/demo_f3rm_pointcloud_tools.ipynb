{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# F3RM Pointcloud Tools Demo\n",
    "\n",
    "This notebook demonstrates how to load and use F3RM pointcloud data and semantic similarity tools.\n",
    "\n",
    "## Prerequisites\n",
    "1. Export pointcloud data using `export_feature_pointcloud.py`\n",
    "2. Optionally align using `align_pointcloud.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from f3rm.semantic_similarity_utils import SemanticPointcloudAnalyzer\n",
    "from f3rm.visualize_feature_pointcloud import FeaturePointcloudData, SemanticSimilarityUtils\n",
    "\n",
    "# Set your data directory\n",
    "data_dir = Path(\"exports/your_pointcloud_data\")  # Change this to your exported data\n",
    "print(f\"Data directory: {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Understanding the Data Structure\n",
    "\n",
    "F3RM pointcloud export creates several files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the exported directory\n",
    "if data_dir.exists():\n",
    "    files = list(data_dir.glob(\"*\"))\n",
    "    for file in sorted(files):\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"{file.name:<30} {size_mb:>8.1f} MB\")\n",
    "else:\n",
    "    print(f\"Data directory {data_dir} not found. Please export pointcloud data first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Loading Metadata\n",
    "\n",
    "The metadata contains export information and data structure details:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine metadata\n",
    "with open(data_dir / \"metadata.json\", 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"Metadata structure:\")\n",
    "for key, value in metadata.items():\n",
    "    if isinstance(value, (list, dict)):\n",
    "        print(f\"{key}: {type(value).__name__} with {len(value)} items\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Loading Point Coordinates\n",
    "\n",
    "The `points.npy` file contains 3D coordinates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point coordinates\n",
    "points = np.load(data_dir / \"points.npy\")\n",
    "\n",
    "print(f\"Points shape: {points.shape}\")\n",
    "print(f\"Points dtype: {points.dtype}\")\n",
    "print(f\"Bounding box: [{points.min(axis=0)}] to [{points.max(axis=0)}]\")\n",
    "print(f\"Mean position: {points.mean(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Loading Feature Vectors\n",
    "\n",
    "Features are stored compressed (float16) by default:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature vectors\n",
    "features_file = metadata['files']['features']\n",
    "features = np.load(data_dir / features_file)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Features dtype: {features.dtype}\")\n",
    "print(f\"Feature range: [{features.min():.3f}, {features.max():.3f}]\")\n",
    "print(f\"Memory usage: {features.nbytes / (1024**2):.1f} MB\")\n",
    "\n",
    "# Convert to float32 if needed for processing\n",
    "if features.dtype == np.float16:\n",
    "    features = features.astype(np.float32)\n",
    "    print(\"Converted to float32 for processing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Loading PCA Parameters\n",
    "\n",
    "PCA parameters ensure consistent feature visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA parameters\n",
    "with open(data_dir / \"pca_params.pkl\", 'rb') as f:\n",
    "    pca_params = pickle.load(f)\n",
    "\n",
    "print(\"PCA parameters:\")\n",
    "for key, value in pca_params.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"{key}: shape {value.shape}, dtype {value.dtype}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Loading PLY Pointclouds\n",
    "\n",
    "RGB and PCA pointclouds are saved as PLY files for visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RGB pointcloud\n",
    "rgb_pcd = o3d.io.read_point_cloud(str(data_dir / \"pointcloud_rgb.ply\"))\n",
    "rgb_points = np.asarray(rgb_pcd.points)\n",
    "rgb_colors = np.asarray(rgb_pcd.colors)\n",
    "\n",
    "print(f\"RGB pointcloud: {len(rgb_points)} points\")\n",
    "print(f\"RGB colors shape: {rgb_colors.shape}, range: [{rgb_colors.min():.3f}, {rgb_colors.max():.3f}]\")\n",
    "\n",
    "# Load PCA pointcloud\n",
    "pca_pcd = o3d.io.read_point_cloud(str(data_dir / \"pointcloud_feature_pca.ply\"))\n",
    "pca_points = np.asarray(pca_pcd.points)\n",
    "pca_colors = np.asarray(pca_pcd.colors)\n",
    "\n",
    "print(f\"PCA pointcloud: {len(pca_points)} points\")\n",
    "print(f\"PCA colors shape: {pca_colors.shape}, range: [{pca_colors.min():.3f}, {pca_colors.max():.3f}]\")\n",
    "\n",
    "# Verify consistency\n",
    "print(f\"Points match: {np.allclose(points, rgb_points)}\")\n",
    "print(f\"RGB/PCA points match: {np.allclose(rgb_points, pca_points)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Using the High-Level Data Loader\n",
    "\n",
    "The `FeaturePointcloudData` class provides convenient access:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the high-level data loader\n",
    "data = FeaturePointcloudData(data_dir)\n",
    "\n",
    "print(data.get_info())\n",
    "\n",
    "# Access data through properties (lazy loading)\n",
    "print(f\"Points shape: {data.points.shape}\")\n",
    "print(f\"Features shape: {data.features.shape}\")\n",
    "print(f\"RGB pointcloud: {len(data.rgb_pointcloud.points)} points\")\n",
    "print(f\"PCA pointcloud: {len(data.pca_pointcloud.points)} points\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Basic Semantic Similarity\n",
    "\n",
    "Using the semantic similarity utilities for queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize semantic analyzer\n",
    "analyzer = SemanticPointcloudAnalyzer(data.features, data.points)\n",
    "\n",
    "# Query for objects (following opt.py approach)\n",
    "query = \"chair\"\n",
    "similarities = analyzer.query_similarity(query, negatives=[\"object\"], softmax_temp=1.0)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"Similarities shape: {similarities.shape}\")\n",
    "print(f\"Similarity range: [{similarities.min():.3f}, {similarities.max():.3f}]\")\n",
    "print(f\"Mean similarity: {similarities.mean():.3f} ± {similarities.std():.3f}\")\n",
    "\n",
    "# Apply threshold (same as opt.py)\n",
    "threshold = 0.502\n",
    "above_threshold = similarities > threshold\n",
    "print(f\"Points above threshold {threshold}: {above_threshold.sum():,} / {len(similarities):,} ({100*above_threshold.mean():.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Object Instance Detection\n",
    "\n",
    "Finding discrete object instances using spatial clustering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find object instances\n",
    "clusters = analyzer.find_object_instances(query, threshold=0.502, min_cluster_size=10, eps=0.05)\n",
    "\n",
    "print(f\"Found {len(clusters)} {query} instances:\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    cluster_points = data.points[cluster]\n",
    "    cluster_sims = similarities[cluster]\n",
    "    center = cluster_points.mean(axis=0)\n",
    "    \n",
    "    print(f\"  {query} {i+1}: {len(cluster)} points at [{center[0]:.2f}, {center[1]:.2f}, {center[2]:.2f}]\")\n",
    "    print(f\"    Similarity: {cluster_sims.mean():.3f} ± {cluster_sims.std():.3f}\")\n",
    "    print(f\"    Bbox: [{cluster_points.min(axis=0)}] to [{cluster_points.max(axis=0)}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Multi-Query Comparison\n",
    "\n",
    "Comparing multiple semantic queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple queries\n",
    "queries = [\"chair\", \"table\", \"book\", \"magazine\", \"wall\", \"floor\"]\n",
    "results = analyzer.compare_queries(queries, threshold=0.502, softmax_temp=1.0)\n",
    "\n",
    "print(\"Query comparison:\")\n",
    "print(f\"{'Query':<12} {'Above Thresh':<12} {'Clusters':<8} {'Max Sim':<8} {'Mean Sim':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for query, result in results.items():\n",
    "    similarities = result['similarities']\n",
    "    above_thresh = result['above_threshold']\n",
    "    num_clusters = len(result['clusters'])\n",
    "    \n",
    "    print(f\"{query:<12} {above_thresh:<12,} {num_clusters:<8} {similarities.max():<8.3f} {similarities.mean():<8.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Spatial Analysis\n",
    "\n",
    "Analyzing spatial distribution of semantic matches:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial analysis for a query\n",
    "spatial_info = analyzer.spatial_analysis(\"chair\", threshold=0.502, softmax_temp=1.0, grid_resolution=0.1)\n",
    "\n",
    "if not spatial_info.get('empty', False):\n",
    "    print(f\"Spatial analysis for '{spatial_info['query']}':\")\n",
    "    print(f\"  Points: {spatial_info['num_points']:,}\")\n",
    "    print(f\"  Bounding box: {spatial_info['bbox_min']} to {spatial_info['bbox_max']}\")\n",
    "    print(f\"  Volume: {spatial_info['volume']:.3f} cubic units\")\n",
    "    print(f\"  Density: {spatial_info['density']:.3f} points per cubic unit\")\n",
    "    print(f\"  Grid cells: {len(spatial_info['grid_stats'])}\")\n",
    "    print(f\"  Score range: [{spatial_info['score_stats']['min']:.3f}, {spatial_info['score_stats']['max']:.3f}]\")\n",
    "else:\n",
    "    print(\"No points found above threshold for spatial analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 12. Direct Semantic Similarity Utils\n",
    "\n",
    "Using the lower-level semantic similarity utilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct usage of SemanticSimilarityUtils\n",
    "semantic_utils = SemanticSimilarityUtils()\n",
    "\n",
    "# Compute similarities directly\n",
    "text_queries = [\"magazine\", \"object\"]  # positive + negatives\n",
    "similarities = semantic_utils.compute_text_similarities(\n",
    "    data.features, text_queries, \n",
    "    has_negatives=True, \n",
    "    softmax_temp=1.0\n",
    ")\n",
    "\n",
    "print(f\"Direct semantic similarity computation:\")\n",
    "print(f\"  Query: {text_queries[0]} vs {text_queries[1:]}\")\n",
    "print(f\"  Shape: {similarities.shape}\")\n",
    "print(f\"  Range: [{similarities.min():.3f}, {similarities.max():.3f}]\")\n",
    "\n",
    "# Create similarity pointcloud\n",
    "sim_pcd = semantic_utils.create_similarity_pointcloud(\n",
    "    data.points, similarities, threshold=0.502, colormap=\"turbo\"\n",
    ")\n",
    "\n",
    "print(f\"  Similarity pointcloud: {len(sim_pcd.points)} points above threshold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 13. Creating Custom Pointclouds\n",
    "\n",
    "Building custom pointclouds with your own colors/filters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom pointcloud with semantic coloring\n",
    "query = \"table\"\n",
    "similarities = analyzer.query_similarity(query, negatives=[\"object\"])\n",
    "\n",
    "# Create mask and colors\n",
    "threshold = 0.502\n",
    "mask = similarities > threshold\n",
    "\n",
    "# Custom coloring: red for matches, blue for non-matches\n",
    "colors = np.zeros((len(data.points), 3))\n",
    "colors[mask] = [1.0, 0.0, 0.0]  # Red for matches\n",
    "colors[~mask] = [0.0, 0.0, 1.0]  # Blue for non-matches\n",
    "\n",
    "# Create pointcloud\n",
    "custom_pcd = o3d.geometry.PointCloud()\n",
    "custom_pcd.points = o3d.utility.Vector3dVector(data.points)\n",
    "custom_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "print(f\"Custom pointcloud created:\")\n",
    "print(f\"  Total points: {len(custom_pcd.points):,}\")\n",
    "print(f\"  Matches (red): {mask.sum():,}\")\n",
    "print(f\"  Non-matches (blue): {(~mask).sum():,}\")\n",
    "\n",
    "# Save custom pointcloud\n",
    "output_path = data_dir / f\"custom_{query}_semantic.ply\"\n",
    "o3d.io.write_point_cloud(str(output_path), custom_pcd)\n",
    "print(f\"  Saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 14. Export Analysis Results\n",
    "\n",
    "Saving comprehensive analysis for external use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive analysis\n",
    "analysis_queries = [\"chair\", \"table\", \"book\", \"magazine\"]\n",
    "output_file = data_dir / \"semantic_analysis.json\"\n",
    "\n",
    "analyzer.export_semantic_analysis(\n",
    "    analysis_queries, \n",
    "    str(output_file), \n",
    "    threshold=0.502, \n",
    "    softmax_temp=1.0\n",
    ")\n",
    "\n",
    "# Load and examine the exported analysis\n",
    "with open(output_file, 'r') as f:\n",
    "    analysis = json.load(f)\n",
    "\n",
    "print(\"Exported analysis structure:\")\n",
    "print(f\"  Metadata keys: {list(analysis['metadata'].keys())}\")\n",
    "print(f\"  Query results: {list(analysis['query_results'].keys())}\")\n",
    "\n",
    "# Show example query result structure\n",
    "first_query = list(analysis['query_results'].keys())[0]\n",
    "query_result = analysis['query_results'][first_query]\n",
    "print(f\"\\nExample query '{first_query}' result structure:\")\n",
    "for key, value in query_result.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}: {list(value.keys())}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value).__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Structure**: Understanding exported files and their contents\n",
    "2. **Loading Data**: Points, features, PLY files, metadata, and PCA parameters\n",
    "3. **High-Level API**: Using `FeaturePointcloudData` for convenient access\n",
    "4. **Semantic Queries**: Computing similarities following opt.py approach\n",
    "5. **Object Detection**: Finding discrete instances with spatial clustering\n",
    "6. **Multi-Query Analysis**: Comparing multiple semantic concepts\n",
    "7. **Spatial Analysis**: Understanding spatial distribution of matches\n",
    "8. **Custom Processing**: Building your own pointclouds and analysis\n",
    "9. **Export Results**: Saving analysis for external algorithms\n",
    "\n",
    "All tools follow the same approach as `opt.py` with direct threshold control and no adaptive logic.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f3rm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
