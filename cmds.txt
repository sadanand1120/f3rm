colmap model_converter --input_path sparse/0 --output_path sparse/0_text --output_type TXT



export HLOC_WORKERS=24 && export CUDA_VISIBLE_DEVICES='0' && export HLOC_LOG_LEVEL=0 && ns-process-data images --data datasets/f3rm/custom/besthome/rawdata/rgb --output-dir datasets/f3rm/custom/besthome/besthome_colmap_all --matching-method vocab_tree --sfm-tool hloc --feature-type superpoint_inloc --matcher-type superglue --num-downscales 0 --no-skip-colmap --no-skip-image-processing --gpu --same-dimensions --verbose --use-sfm-depth

export HLOC_WORKERS=24 && export CUDA_VISIBLE_DEVICES='0' && export HLOC_LOG_LEVEL=0 && ns-process-data video   --data sittingroom.MOV --output-dir datasets/f3rm/custom/besthome/besthome_colmap_all --matching-method vocab_tree --sfm-tool hloc --feature-type superpoint_inloc --matcher-type superglue --num-downscales 0 --no-skip-colmap --no-skip-image-processing --gpu --same-dimensions --verbose --use-sfm-depth --num-frames-target 3072

export HLOC_WORKERS=24 && export CUDA_VISIBLE_DEVICES='0' && export HLOC_LOG_LEVEL=0 && ns-process-data record3d --data datasets/f3rm/custom/besthome/rawdata --output-dir datasets/f3rm/custom/besthome --verbose --num-downscales 0 --max-dataset-size -1




export CUDA_VISIBLE_DEVICES='3' && python3 f3rm/features/extract_features_standalone.py --data datasets/f3rm/custom/ahglabentry --feature-type CLIP



export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True && export CUDA_VISIBLE_DEVICES='0,1,2,3' && ns-train f3rm --max-num-iterations 120000 --pipeline.datamanager.train-num-images-to-sample-from 32 --pipeline.datamanager.train-num-times-to-repeat-images 512 --pipeline.datamanager.eval-num-images-to-sample-from 32 --pipeline.datamanager.eval-num-times-to-repeat-images 512 --machine.num-devices 4 --vis wandb --data datasets/f3rm/custom/ahgroom/ahgroom_colmap --pipeline.datamanager.feature-type CLIP --output-dir outputs --experiment-name homenew --pipeline.model.feat-hidden-dim 64 --pipeline.model.feat-num-layers 2

export <...above...> --pipeline.model.feat-num-layers 2 --load-dir dense_outputs/dinoclip/f3rm/2025-05-18_185942/nerfstudio_models

export <...above...> --pipeline.model.feat-num-layers 2 nerfstudio-data --orientation-method none --center-method none --auto-scale-poses False --scale-factor 1.0 --scene-scale 1.0




ns-export pointcloud --load-config outputs/sittingroom/f3rm/2025-04-07_123618/config.yml --output-dir exports/sitting_pcd/ --num-points 50000000 --remove-outliers True --normal-method open3d --use-bounding-box True --bounding-box-min -1 -1 -1 --bounding-box-max 1 1 1



unset CUDA_VISIBLE_DEVICES && ns-viewer --load-config outputs/home/f3rm/2025-04-06_131604/config.yml



conda activate gpuprofile && python3 gpu_tracker.py --user smodak --gpu 0 1 2 3 --interval 1 --file rec_ahgroom_colmap_1362216_dinoclip_nodetachconfig.csv --mode record